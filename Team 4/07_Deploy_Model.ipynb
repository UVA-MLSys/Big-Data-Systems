{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = 'tensorflow-training-2024-04-20-05-32-55-117'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-211125778552/tensorflow-training-2024-04-21-01-56-36-032/output/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-us-east-1-211125778552/tensorflow-training-2024-04-21-01-56-36-032/output/model.tar.gz ./model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "code/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/validation/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/validation/events.out.tfevents.1713665898.ip-10-2-64-28.ec2.internal.90.28606.v2\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/validation/events.out.tfevents.1713665659.ip-10-2-64-28.ec2.internal.90.25864.v2\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/events.out.tfevents.1713664780.ip-10-2-64-28.ec2.internal.profile-empty\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/plugins/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/plugins/profile/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/plugins/profile/2024_04_21_01_59_40/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/plugins/profile/2024_04_21_01_59_40/ip-10-2-64-28.ec2.internal.trace.json.gz\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/plugins/profile/2024_04_21_01_59_40/ip-10-2-64-28.ec2.internal.input_pipeline.pb\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/plugins/profile/2024_04_21_01_59_40/ip-10-2-64-28.ec2.internal.memory_profile.json.gz\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/plugins/profile/2024_04_21_01_59_40/ip-10-2-64-28.ec2.internal.overview_page.pb\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/plugins/profile/2024_04_21_01_59_40/ip-10-2-64-28.ec2.internal.xplane.pb\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/plugins/profile/2024_04_21_01_59_40/ip-10-2-64-28.ec2.internal.tensorflow_stats.pb\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/plugins/profile/2024_04_21_01_59_40/ip-10-2-64-28.ec2.internal.kernel_stats.pb\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/events.out.tfevents.1713664731.ip-10-2-64-28.ec2.internal.90.5924.v2\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorboard/train/events.out.tfevents.1713665898.ip-10-2-64-28.ec2.internal.90.28586.v2\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorflow/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorflow/saved_model/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorflow/saved_model/0/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorflow/saved_model/0/saved_model.pb\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorflow/saved_model/0/variables/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorflow/saved_model/0/variables/variables.data-00000-of-00001\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorflow/saved_model/0/variables/variables.index\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tensorflow/saved_model/0/assets/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "transformers/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "transformers/fine-tuned/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "transformers/fine-tuned/config.json\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "transformers/fine-tuned/tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./model/\n",
    "!tar -xvzf ./model.tar.gz -C ./model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-21 02:37:40.608942: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2024-04-21 02:37:40.608977: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_ids'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1, 183)\n",
      "        name: serving_default_input_ids:0\n",
      "    inputs['input_mask'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1, 183)\n",
      "        name: serving_default_input_mask:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 2)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: list\n",
      "          Value: [TensorSpec(shape=(None, 183), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 183), dtype=tf.int32, name='input_mask')]\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: list\n",
      "          Value: [TensorSpec(shape=(None, 183), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 183), dtype=tf.int32, name='inputs/1')]\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: list\n",
      "          Value: [TensorSpec(shape=(None, 183), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 183), dtype=tf.int32, name='input_mask')]\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: list\n",
      "          Value: [TensorSpec(shape=(None, 183), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 183), dtype=tf.int32, name='inputs/1')]\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: list\n",
      "          Value: [TensorSpec(shape=(None, 183), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 183), dtype=tf.int32, name='input_mask')]\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: list\n",
      "          Value: [TensorSpec(shape=(None, 183), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 183), dtype=tf.int32, name='inputs/1')]\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: list\n",
      "          Value: [TensorSpec(shape=(None, 183), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 183), dtype=tf.int32, name='input_mask')]\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: list\n",
      "          Value: [TensorSpec(shape=(None, 183), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 183), dtype=tf.int32, name='input_mask')]\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: list\n",
      "          Value: [TensorSpec(shape=(None, 183), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 183), dtype=tf.int32, name='inputs/1')]\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --all --dir ./model/tensorflow/saved_model/0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying to REST Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow-training-2024-04-20-05-32-55-117-tf-1713674056'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = int(time.time())\n",
    "tf_model_name = f\"{training_job_name}-tf-{timestamp}\"\n",
    "tf_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = TensorFlowModel(\n",
    "    name = tf_model_name,\n",
    "    source_dir = 'src',\n",
    "    entry_point = 'inference.py',\n",
    "    model_data = f's3://{bucket}/{training_job_name}/output/model.tar.gz',\n",
    "    role = role,\n",
    "    framework_version = '2.3.1'   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Using already existing model: tensorflow-training-2024-04-20-05-32-55-117-tf-1713674056\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateEndpoint operation: Cannot create already existing endpoint \"arn:aws:sagemaker:us-east-1:211125778552:endpoint/tensorflow-training-2024-04-20-05-32-55-117-tf-1713674056\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23974/3508923143.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minitial_instance_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minstance_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ml.c4.xlarge'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/.conda/envs/data_science_on_aws/lib/python3.7/site-packages/sagemaker/tensorflow/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, update_endpoint)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         )\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data_science_on_aws/lib/python3.7/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             \u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m         )\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data_science_on_aws/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   3454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3455\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3456\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data_science_on_aws/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   2954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m         self.sagemaker_client.create_endpoint(\n\u001b[0;32m-> 2956\u001b[0;31m             \u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2957\u001b[0m         )\n\u001b[1;32m   2958\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data_science_on_aws/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 )\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data_science_on_aws/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1007\u001b[0m             )\n\u001b[1;32m   1008\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateEndpoint operation: Cannot create already existing endpoint \"arn:aws:sagemaker:us-east-1:211125778552:endpoint/tensorflow-training-2024-04-20-05-32-55-117-tf-1713674056\"."
     ]
    }
   ],
   "source": [
    "tf_model.deploy(\n",
    "    endpoint_name = tf_model_name,\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.c4.xlarge',\n",
    "    wait = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEMO: Predicting customer satisfaction on future comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowPredictor\n",
    "from sagemaker.serializers import JSONLinesSerializer\n",
    "from sagemaker.deserializers import JSONLinesDeserializer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "content_type is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "predictor = TensorFlowPredictor(\n",
    "    endpoint_name = tf_model_name,\n",
    "    sagemaker_session = sess,\n",
    "    model_name = \"saved_model\",\n",
    "    serializer = JSONLinesSerializer(),\n",
    "    deserializer = JSONLinesDeserializer(),\n",
    "    content_type = 'application/jsonlines',\n",
    "    accept_type = 'application/jsonlines'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation: Recommended\n",
      "Recommendation: Not Recommended\n",
      "Recommendation: Recommended\n"
     ]
    }
   ],
   "source": [
    "review1 = '''I wholeheartedly recommend the RyanAir experience to anyone! \n",
    "The seats were comfortable, and everyone was so friendly.'''\n",
    "\n",
    "review2 = '''I was not happy with how I was treated in this last flight. \n",
    "The in-flight entertainment consoles were broken, and I was treated rudely.'''\n",
    "\n",
    "review3 = '''Overall, a nice journey. The seats were a little worn down, and I had to exchange seats,\n",
    " but I was given a discount on my tickets and overall am happy with my decision.'''\n",
    "\n",
    "inputs = [{\"features\": [review1]}, {\"features\": [review2]}, {\"features\": [review3]}]\n",
    "\n",
    "predicted_classes = predictor.predict(inputs)\n",
    "\n",
    "\n",
    "for predicted_class in predicted_classes:\n",
    "    print(\"Recommendation: {}\".format(predicted_class['predicted_label']).replace('1', 'Not Recommended').replace('5', 'Recommended'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science_on_aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
