{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Redshift Data Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade boto3\n",
    "#!pip install awswrangler\n",
    "#!pip list | grep boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# Get region \n",
    "session = boto3.session.Session()\n",
    "region_name = session.region_name\n",
    "\n",
    "# Get SageMaker session & default S3 bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "redshift = boto3.client('redshift')\n",
    "secretsmanager = boto3.client('secretsmanager')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "secret = secretsmanager.get_secret_value(SecretId='team3_redshift_login')\n",
    "cred = json.loads(secret['SecretString'])\n",
    "\n",
    "master_user_name = cred[0]['username']\n",
    "master_user_pw = cred[1]['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team3\n"
     ]
    }
   ],
   "source": [
    "redshift_cluster_identifier = 'team3'\n",
    "\n",
    "database_name_redshift = 'dev'\n",
    "\n",
    "redshift_port = '5439'\n",
    "\n",
    "schema_redshift = 'redshift'\n",
    "\n",
    "print(master_user_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "response = redshift.describe_clusters(ClusterIdentifier=redshift_cluster_identifier)\n",
    "cluster_status = response['Clusters'][0]['ClusterStatus']\n",
    "print(cluster_status)\n",
    "\n",
    "while cluster_status != 'available':\n",
    "    time.sleep(10)\n",
    "    response = redshift.describe_clusters(ClusterIdentifier=redshift_cluster_identifier)\n",
    "    cluster_status = response['Clusters'][0]['ClusterStatus']\n",
    "    print(cluster_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redshift endpoint: team3.cgkvnybhfypi.us-east-1.redshift.amazonaws.com\n",
      "IAM Role: arn:aws:iam::211125778552:role/team3-Redshift-role\n"
     ]
    }
   ],
   "source": [
    "redshift_endpoint_address = response['Clusters'][0]['Endpoint']['Address']\n",
    "iam_role = response['Clusters'][0]['IamRoles'][0]['IamRoleArn']\n",
    "\n",
    "print('Redshift endpoint: {}'.format(redshift_endpoint_address))\n",
    "print('IAM Role: {}'.format(iam_role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ClusterIdentifier': 'team3', 'NodeType': 'dc2.large', 'ClusterStatus': 'available', 'ClusterAvailabilityStatus': 'Available', 'MasterUsername': 'team3', 'DBName': 'dev', 'Endpoint': {'Address': 'team3.cgkvnybhfypi.us-east-1.redshift.amazonaws.com', 'Port': 5439}, 'ClusterCreateTime': datetime.datetime(2024, 4, 7, 20, 43, 19, 265000, tzinfo=tzlocal()), 'AutomatedSnapshotRetentionPeriod': 1, 'ManualSnapshotRetentionPeriod': -1, 'ClusterSecurityGroups': [], 'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-07248e327a8dc9548', 'Status': 'active'}], 'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0', 'ParameterApplyStatus': 'in-sync'}], 'ClusterSubnetGroupName': 'default', 'VpcId': 'vpc-0a19e74ac58edb30f', 'AvailabilityZone': 'us-east-1a', 'PreferredMaintenanceWindow': 'mon:03:00-mon:03:30', 'PendingModifiedValues': {}, 'ClusterVersion': '1.0', 'AllowVersionUpgrade': True, 'NumberOfNodes': 2, 'PubliclyAccessible': False, 'Encrypted': False, 'ClusterPublicKey': 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDiRLD9XijNCNiDc5JQhX1kbi0oqjzMFp7n8cr6CEMSlD+RETXJG2SkkXvDvMqjJ+1Rpjpvzd96vFEAm+qmfKFdw28+70FUWYk7Xgvi3OL3v5rzfzWFJVXQgNR0BJjxqBycTTjM2t7HLUYnWdy8k6iaNj6lhr7lC1HO/PWC1BMIFKtJL1/wvNookfMYevB/gZVkGJzSdsYkv2E/L4G53d0dLBkMYSwNEIpyci9jpE38HWERmuaiNI6T3h5v85UNWzJS5gV3H4uNCXfxBe/6PFTKelJm6/9gncggExeTCuAPv+No0morUqJWifbUcLoGaxSQzSmpXykKWss/KPnZx1ex Amazon-Redshift\\n', 'ClusterNodes': [{'NodeRole': 'LEADER', 'PrivateIPAddress': '172.31.24.249', 'PublicIPAddress': '52.54.40.85'}, {'NodeRole': 'COMPUTE-0', 'PrivateIPAddress': '172.31.30.136', 'PublicIPAddress': '54.152.160.58'}, {'NodeRole': 'COMPUTE-1', 'PrivateIPAddress': '172.31.16.76', 'PublicIPAddress': '34.198.46.183'}], 'ClusterRevisionNumber': '63269', 'Tags': [], 'EnhancedVpcRouting': False, 'IamRoles': [{'IamRoleArn': 'arn:aws:iam::211125778552:role/team3-Redshift-role', 'ApplyStatus': 'in-sync'}], 'MaintenanceTrackName': 'current', 'ElasticResizeNumberOfNodeOptions': '[4]', 'DeferredMaintenanceWindows': [], 'NextMaintenanceWindowStartTime': datetime.datetime(2024, 4, 8, 3, 0, tzinfo=tzlocal()), 'AvailabilityZoneRelocationStatus': 'disabled', 'ClusterNamespaceArn': 'arn:aws:redshift:us-east-1:211125778552:namespace:378805e0-0321-410f-8b31-5797787696ec', 'TotalStorageCapacityInMegaBytes': 800000, 'AquaConfiguration': {'AquaStatus': 'disabled', 'AquaConfigurationStatus': 'auto'}, 'MultiAZ': 'Disabled'}]\n"
     ]
    }
   ],
   "source": [
    "print(response['Clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import awswrangler as wr\n",
    "\n",
    "con_redshift = wr.data_api.redshift.connect(\n",
    "    cluster_id=redshift_cluster_identifier,\n",
    "    database=database_name_redshift,\n",
    "    db_user=master_user_name,\n",
    ")\n",
    "\n",
    "schema_redshift = 'team3'\n",
    "\n",
    "statement = \"\"\"CREATE SCHEMA IF NOT EXISTS {}\"\"\".format(schema_redshift)\n",
    "\n",
    "wr.data_api.redshift.read_sql_query(\n",
    "    sql=statement,\n",
    "    con=con_redshift,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Redhisft_role ='team3-Redshift-role'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query=\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS team3.output_csv_gzip (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS team3.output_csv_lz (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS team3.output_csv_snappy (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS team3.output_json_gzip (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS team3.output_json_lz (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS team3.output_json_snappy  (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS team3.output_orc_snappy (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "CREATE TABLE IF NOT EXISTS team3.output_orc_zlib (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "CREATE TABLE IF NOT EXISTS team3.output_parquet_gzip (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS team3.output_parquet_lz4 (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS team3.output_parquet_lzo (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "CREATE TABLE IF NOT EXISTS team3.output_parquet_snappy (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS team3.output_parquet_zstd (\n",
    "                finaldisposition varchar(256), sentencetime bigint, court varchar(256), complainant varchar(256), publicdefender boolean, gender varchar(256), race varchar(256), casetype varchar(256), class varchar(256), codesection varchar(256), chargeamended boolean\n",
    "            );\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating table output_parquet_zstd: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Establish connections\n",
    "glue = boto3.client('glue')\n",
    "redshift = boto3.client('redshift-data')\n",
    "\n",
    "# Define Glue database and Redshift schema\n",
    "glue_database = 'team3-court-data'\n",
    "redshift_schema = schema_redshift\n",
    "\n",
    "# Get table list from Glue Catalog\n",
    "tables = glue.get_tables(DatabaseName=glue_database)['TableList']\n",
    "\n",
    "# Execute CREATE TABLE query\n",
    "try:\n",
    "    redshift.execute_statement(\n",
    "        ClusterIdentifier='YOUR_REDSHIFT_CLUSTER_ID',\n",
    "        Database='YOUR_REDSHIFT_DATABASE_NAME',\n",
    "        DbUser='YOUR_REDSHIFT_USER',\n",
    "        Sql=create_table_query\n",
    "        )\n",
    "    print(f\"Table {table_name} created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating table {table_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.model_data_csv (\n",
      "                finaldisposition string, sentencetime bigint, court string, complainant string, publicdefender boolean, gender string, race string, casetype string, class string, codesection string, chargeamended boolean\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.model_data_csv\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/model_data.csv'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table model_data_csv: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table model_data_csv loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.model_data_csv_gz (\n",
      "                finaldisposition string, sentencetime bigint, court string, complainant string, publicdefender boolean, gender string, race string, casetype string, class string, codesection string, chargeamended boolean\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.model_data_csv_gz\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/model_data.csv.gz'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table model_data_csv_gz: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table model_data_csv_gz loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_csv_gzip (\n",
      "                col0 string, col1 bigint, col2 string, col3 string, col4 boolean, col5 string, col6 string, col7 string, col8 string, col9 string, col10 boolean\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_csv_gzip\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_csv_gzip/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_csv_gzip: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_csv_gzip loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_csv_lz (\n",
      "                \n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_csv_lz\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_csv_lz/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_csv_lz: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_csv_lz loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_csv_snappy (\n",
      "                col0 string, col1 bigint, col2 string, col3 string, col4 boolean, col5 string, col6 string, col7 string, col8 string, col9 string, col10 boolean\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_csv_snappy\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_csv_snappy/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_csv_snappy: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_csv_snappy loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_json_gzip (\n",
      "                finaldisposition string, sentencetime string, court string, complainant string, publicdefender string, gender string, race string, casetype string, class string, codesection string, chargeamended string\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_json_gzip\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_json_gzip/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_json_gzip: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_json_gzip loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_json_lz (\n",
      "                \n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_json_lz\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_json_lz/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_json_lz: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_json_lz loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_json_snappy (\n",
      "                finaldisposition string, sentencetime string, court string, complainant string, publicdefender string, gender string, race string, casetype string, class string, codesection string, chargeamended string\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_json_snappy\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_json_snappy/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_json_snappy: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_json_snappy loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_orc_snappy (\n",
      "                finaldisposition string, sentencetime string, court string, complainant string, publicdefender string, gender string, race string, casetype string, class string, codesection string, chargeamended string\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_orc_snappy\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_orc_snappy/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_orc_snappy: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_orc_snappy loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_orc_zlib (\n",
      "                finaldisposition string, sentencetime string, court string, complainant string, publicdefender string, gender string, race string, casetype string, class string, codesection string, chargeamended string\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_orc_zlib\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_orc_zlib/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_orc_zlib: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_orc_zlib loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_parquet_gzip (\n",
      "                finaldisposition string, sentencetime string, court string, complainant string, publicdefender string, gender string, race string, casetype string, class string, codesection string, chargeamended string\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_parquet_gzip\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_parquet_gzip/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_parquet_gzip: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_parquet_gzip loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_parquet_lz4 (\n",
      "                finaldisposition string, sentencetime string, court string, complainant string, publicdefender string, gender string, race string, casetype string, class string, codesection string, chargeamended string\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_parquet_lz4\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_parquet_lz4/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_parquet_lz4: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_parquet_lz4 loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_parquet_lzo (\n",
      "                finaldisposition string, sentencetime string, court string, complainant string, publicdefender string, gender string, race string, casetype string, class string, codesection string, chargeamended string\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_parquet_lzo\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_parquet_lzo/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_parquet_lzo: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_parquet_lzo loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_parquet_snappy (\n",
      "                finaldisposition string, sentencetime string, court string, complainant string, publicdefender string, gender string, race string, casetype string, class string, codesection string, chargeamended string\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_parquet_snappy\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_parquet_snappy/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_parquet_snappy: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_parquet_snappy loaded successfully.\n",
      "\n",
      "            CREATE TABLE IF NOT EXISTS team3.output_parquet_zstd (\n",
      "                finaldisposition string, sentencetime string, court string, complainant string, publicdefender string, gender string, race string, casetype string, class string, codesection string, chargeamended string\n",
      "            );\n",
      "        \n",
      "\n",
      "            COPY team3.output_parquet_zstd\n",
      "            FROM 's3://s3://team-3-project-data/convrted-data/redshift-ingestion/output_parquet_zstd/'\n",
      "            iam_role 'team3-Redshift-role'\n",
      "            FORMAT AS PARQUET\n",
      "            IGNOREHEADER 1\n",
      "            CSV QUOTE AS '\"'\n",
      "            EMPTYASNULL\n",
      "            BLANKSASNULL;\n",
      "        \n",
      "Error creating table output_parquet_zstd: An error occurred (ValidationException) when calling the ExecuteStatement operation: Redshift endpoint doesn't exist in this region.\n",
      "Table output_parquet_zstd loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Establish connections\n",
    "glue = boto3.client('glue')\n",
    "redshift = boto3.client('redshift-data')\n",
    "\n",
    "# Define Glue database and Redshift schema\n",
    "glue_database = 'team3-court-data'\n",
    "redshift_schema = schema_redshift\n",
    "\n",
    "# Get table list from Glue Catalog\n",
    "tables = glue.get_tables(DatabaseName=glue_database)['TableList']\n",
    "\n",
    "# Iterate through tables and load data into Redshift\n",
    "for table in tables:\n",
    "    table_name = table['Name']\n",
    "    table_location = table.get('StorageDescriptor', {}).get('Location')\n",
    "\n",
    "    if table_location:\n",
    "        # Construct column definitions\n",
    "        column_definitions = []\n",
    "        columns = table.get('StorageDescriptor', {}).get('Columns', [])\n",
    "        for col in columns:\n",
    "            col_name = col['Name']\n",
    "            col_type = col['Type']\n",
    "            column_definitions.append(f\"{col_name} {col_type}\")\n",
    "\n",
    "        # Construct CREATE TABLE query\n",
    "        create_table_query = f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {redshift_schema}.{table_name} (\n",
    "                {', '.join(column_definitions)}\n",
    "            );\n",
    "        \"\"\"\n",
    "\n",
    "        print(create_table_query)\n",
    "    \n",
    "        # Construct COPY query with error handling and logging\n",
    "        copy_query = f\"\"\"\n",
    "            COPY {redshift_schema}.{table_name}\n",
    "            FROM 's3://{table_location}'\n",
    "            iam_role team3-Redshift-role\n",
    "            FORMAT AS PARQUET\n",
    "            IGNOREHEADER 1\n",
    "            EMPTYASNULL\n",
    "            BLANKSASNULL;\n",
    "        \"\"\"\n",
    "\n",
    "        print(copy_query)\n",
    "\n",
    "        # Execute CREATE TABLE query\n",
    "        try:\n",
    "            redshift.execute_statement(\n",
    "                ClusterIdentifier='YOUR_REDSHIFT_CLUSTER_ID',\n",
    "                Database='YOUR_REDSHIFT_DATABASE_NAME',\n",
    "                DbUser='YOUR_REDSHIFT_USER',\n",
    "                Sql=create_table_query\n",
    "            )\n",
    "            print(f\"Table {table_name} created successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating table {table_name}: {e}\")\n",
    "\n",
    "        try:\n",
    "            redshift.execute_statement(\n",
    "                ClusterIdentifier='team3',\n",
    "                Database='court-data',\n",
    "                DbUser='team3',\n",
    "                Sql=copy_query\n",
    "            )\n",
    "            print(f\"Table {table_name} loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading table {table_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"Table {table_name} does not have a StorageDescriptor with Location. Skipping...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Columns': [{'Name': 'finaldisposition', 'Type': 'string'}, {'Name': 'sentencetime', 'Type': 'bigint'}, {'Name': 'court', 'Type': 'string'}, {'Name': 'complainant', 'Type': 'string'}, {'Name': 'publicdefender', 'Type': 'boolean'}, {'Name': 'gender', 'Type': 'string'}, {'Name': 'race', 'Type': 'string'}, {'Name': 'casetype', 'Type': 'string'}, {'Name': 'class', 'Type': 'string'}, {'Name': 'codesection', 'Type': 'string'}, {'Name': 'chargeamended', 'Type': 'boolean'}], 'Location': 's3://team-3-project-data/convrted-data/redshift-ingestion/model_data.csv', 'InputFormat': 'org.apache.hadoop.mapred.TextInputFormat', 'OutputFormat': 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat', 'Compressed': False, 'NumberOfBuckets': -1, 'SerdeInfo': {'SerializationLibrary': 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe', 'Parameters': {'field.delim': ','}}, 'BucketColumns': [], 'SortColumns': [], 'Parameters': {'skip.header.line.count': '1', 'sizeKey': '807368614', 'UPDATED_BY_CRAWLER': 'team3-data-crawler', 'CrawlerSchemaSerializerVersion': '1.0', 'recordCount': '7339714', 'averageRecordSize': '110', 'CrawlerSchemaDeserializerVersion': '1.0', 'compressionType': 'none', 'classification': 'csv', 'columnsOrdered': 'true', 'areColumnsQuoted': 'false', 'delimiter': ',', 'typeOfData': 'file'}, 'StoredAsSubDirectories': False}\n"
     ]
    }
   ],
   "source": [
    "print(glue.get_table(DatabaseName=glue_database, Name='model_data_csv')['Table']['StorageDescriptor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "response = redshift.describe_clusters(ClusterIdentifier=redshift_cluster_identifier)\n",
    "cluster_status = response['Clusters'][0]['ClusterStatus']\n",
    "print(cluster_status)\n",
    "\n",
    "while cluster_status != 'available':\n",
    "    time.sleep(10)\n",
    "    response = redshift.describe_clusters(ClusterIdentifier=redshift_cluster_identifier)\n",
    "    cluster_status = response['Clusters'][0]['ClusterStatus']\n",
    "    print(cluster_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redshift endpoint: team3.cgkvnybhfypi.us-east-1.redshift.amazonaws.com\n",
      "IAM Role: arn:aws:iam::211125778552:role/team3-Redshift-role\n"
     ]
    }
   ],
   "source": [
    "redshift_endpoint_address = response['Clusters'][0]['Endpoint']['Address']\n",
    "iam_role = response['Clusters'][0]['IamRoles'][0]['IamRoleArn']\n",
    "\n",
    "print('Redshift endpoint: {}'.format(redshift_endpoint_address))\n",
    "print('IAM Role: {}'.format(iam_role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "\n",
    "con_redshift = wr.data_api.redshift.connect(\n",
    "    cluster_id=redshift_cluster_identifier,\n",
    "    database=database_name_redshift,\n",
    "    db_user=master_user_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Athena Database \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_athena = 'team3-court-data'\n",
    "database_name_athena = 'team3-court-data'\n",
    "#arn:aws:iam::211125778552:role/team3-Redshift-role\n",
    "iam_role ='arn:aws:iam::211125778552:role/team3-Redshift-role' \n",
    "region_name='us-east-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE EXTERNAL SCHEMA IF NOT EXISTS team3-court-data FROM DATA CATALOG \n",
      "    DATABASE 'team3-court-data' \n",
      "    IAM_ROLE 'team3-Redshift-role'\n",
      "    REGION 'us-east-1'\n",
      "    CREATE EXTERNAL DATABASE IF NOT EXISTS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "statement = \"\"\"\n",
    "CREATE EXTERNAL SCHEMA IF NOT EXISTS {} FROM DATA CATALOG \n",
    "    DATABASE '{}' \n",
    "    IAM_ROLE '{}'\n",
    "    REGION '{}'\n",
    "    CREATE EXTERNAL DATABASE IF NOT EXISTS\n",
    "\"\"\".format(schema_athena, database_name_athena, iam_role, region_name)\n",
    "\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RedshiftDataApiFailedException",
     "evalue": "Request 3a9e276c-5a4d-4157-93a4-3c7446260395 failed with status FAILED and error ERROR: syntax error at or near \"-\"\n  Position: 44",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRedshiftDataApiFailedException\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/Big-Data-Systems/Team 3/data conversion/redshift-data-load.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://bzwowb6vxnonufp.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Big-Data-Systems/Team%203/data%20conversion/redshift-data-load.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m wr\u001b[39m.\u001b[39;49mdata_api\u001b[39m.\u001b[39;49mredshift\u001b[39m.\u001b[39;49mread_sql_query(\n\u001b[1;32m      <a href='vscode-notebook-cell://bzwowb6vxnonufp.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Big-Data-Systems/Team%203/data%20conversion/redshift-data-load.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     sql\u001b[39m=\u001b[39;49mstatement,\n\u001b[1;32m      <a href='vscode-notebook-cell://bzwowb6vxnonufp.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Big-Data-Systems/Team%203/data%20conversion/redshift-data-load.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     con\u001b[39m=\u001b[39;49mcon_redshift,\n\u001b[1;32m      <a href='vscode-notebook-cell://bzwowb6vxnonufp.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Big-Data-Systems/Team%203/data%20conversion/redshift-data-load.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/awswrangler/data_api/redshift.py:304\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, database)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_sql_query\u001b[39m(sql: \u001b[39mstr\u001b[39m, con: RedshiftDataApi, database: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run an SQL query on a RedshiftDataApi connection and return the result as a DataFrame.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39m    A Pandas DataFrame containing the query results.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m     \u001b[39mreturn\u001b[39;00m con\u001b[39m.\u001b[39;49mexecute(sql, database\u001b[39m=\u001b[39;49mdatabase)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/awswrangler/data_api/_connector.py:39\u001b[0m, in \u001b[0;36mDataApiConnector.execute\u001b[0;34m(self, sql, database, transaction_id, parameters)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute SQL statement against a Data API Service.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mA Pandas DataFrame containing the execution results.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m request_id: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_statement(\n\u001b[1;32m     37\u001b[0m     sql, database\u001b[39m=\u001b[39mdatabase, transaction_id\u001b[39m=\u001b[39mtransaction_id, parameters\u001b[39m=\u001b[39mparameters\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 39\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_statement_result(request_id)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/awswrangler/data_api/redshift.py:152\u001b[0m, in \u001b[0;36mRedshiftDataApi._get_statement_result\u001b[0;34m(self, request_id)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_statement_result\u001b[39m(\u001b[39mself\u001b[39m, request_id: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwaiter\u001b[39m.\u001b[39;49mwait(request_id)\n\u001b[1;32m    153\u001b[0m     describe_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mdescribe_statement(Id\u001b[39m=\u001b[39mrequest_id)\n\u001b[1;32m    154\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m describe_response[\u001b[39m\"\u001b[39m\u001b[39mHasResultSet\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/awswrangler/data_api/redshift.py:219\u001b[0m, in \u001b[0;36mRedshiftDataApiWaiter.wait\u001b[0;34m(self, request_id)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m status \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mABORTED\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFAILED\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    218\u001b[0m     error \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 219\u001b[0m     \u001b[39mraise\u001b[39;00m RedshiftDataApiFailedException(\n\u001b[1;32m    220\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRequest \u001b[39m\u001b[39m{\u001b[39;00mrequest_id\u001b[39m}\u001b[39;00m\u001b[39m failed with status \u001b[39m\u001b[39m{\u001b[39;00mstatus\u001b[39m}\u001b[39;00m\u001b[39m and error \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m     )\n\u001b[1;32m    222\u001b[0m _logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mStatement execution status \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m - sleeping for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m\"\u001b[39m, status, sleep)\n\u001b[1;32m    223\u001b[0m time\u001b[39m.\u001b[39msleep(sleep)\n",
      "\u001b[0;31mRedshiftDataApiFailedException\u001b[0m: Request 3a9e276c-5a4d-4157-93a4-3c7446260395 failed with status FAILED and error ERROR: syntax error at or near \"-\"\n  Position: 44"
     ]
    }
   ],
   "source": [
    "wr.data_api.redshift.read_sql_query(\n",
    "    sql=statement,\n",
    "    con=con_redshift,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.data_api.redshift.read_sql_query(\n",
    "    sql=statement,\n",
    "    con=con_redshift,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
